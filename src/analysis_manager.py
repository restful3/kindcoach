"""
ë¶„ì„ ê²°ê³¼ ê´€ë¦¬ ì‹œìŠ¤í…œ
ëª¨ë“  ë¶„ì„ ìœ í˜•ì˜ ê²°ê³¼ë¥¼ ì €ì¥, ë¡œë“œ, ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Optional, Any
from pathlib import Path
import glob


class AnalysisManager:
    """ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, results_dir: str = "data/analysis_results"):
        """
        ë¶„ì„ ê´€ë¦¬ì ì´ˆê¸°í™”
        
        Args:
            results_dir: ë¶„ì„ ê²°ê³¼ ì €ì¥ ë””ë ‰í„°ë¦¬
        """
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # ê³µí†µ ë””ë ‰í„°ë¦¬ (í•˜ìœ„ í˜¸í™˜ì„±)
        self.shared_dir = self.results_dir / "shared"
        self.shared_dir.mkdir(exist_ok=True)
        
        # ì§€ì›í•˜ëŠ” ë¶„ì„ ìœ í˜•
        self.analysis_types = {
            "comprehensive": {
                "name": "ì¢…í•© ë¶„ì„",
                "description": "êµì‚¬-ì•„ë™ ëŒ€í™”ì˜ ì „ë©´ì ì¸ ë¶„ì„ê³¼ ìƒì„¸í•œ ì½”ì¹­ í”¼ë“œë°±",
                "icon": "ğŸ“Š"
            },
            "quick_feedback": {
                "name": "ë¹ ë¥¸ í”¼ë“œë°±",
                "description": "ì¦‰ì„ì—ì„œ í•µì‹¬ì ì¸ í”¼ë“œë°±ì„ ê°„ë‹¨í•˜ê²Œ ì œê³µ",
                "icon": "âš¡"
            },
            "child_development": {
                "name": "ì•„ë™ ë°œë‹¬ ë¶„ì„",
                "description": "ë°œë‹¬ ì‹¬ë¦¬í•™ ê´€ì ì—ì„œ ì•„ë™ì˜ í˜„ì¬ ìƒíƒœë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ë¶„ì„",
                "icon": "ğŸ‘¶"
            },
            "coaching_tips": {
                "name": "ìƒí™©ë³„ ì½”ì¹­ íŒ",
                "description": "êµ¬ì²´ì ì¸ êµì‚¬ ì½”ì¹­ ê°€ì´ë“œì™€ ì‹¤ë¬´ íŒ ì œê³µ",
                "icon": "ğŸ’¡"
            },
            "sentiment_interpretation": {
                "name": "ê°ì • í•´ì„",
                "description": "ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ êµìœ¡ì  ê´€ì ì—ì„œ í•´ì„í•˜ê³  í™œìš© ë°©ì•ˆ ì œì‹œ",
                "icon": "ğŸ˜Š"
            }
        }
    
    def create_new_analysis(self, conversation_id: str, transcription_data: Dict[str, Any], 
                          teacher_child_analysis: Dict[str, Any], 
                          metadata: Optional[Dict[str, Any]] = None,
                          username: Optional[str] = None) -> Dict[str, Any]:
        """
        ìƒˆë¡œìš´ ë¶„ì„ ì„¸ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            conversation_id: ëŒ€í™” ID
            transcription_data: ì „ì‚¬ ë°ì´í„°
            teacher_child_analysis: êµì‚¬-ì•„ë™ êµ¬ë¶„ ë¶„ì„
            
        Returns:
            Dict: ìƒì„±ëœ ë¶„ì„ ì„¸ì…˜ ë°ì´í„°
        """
        analysis_data = {
            "conversation_id": conversation_id,
            "created_at": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat(),
            "username": username,
            "metadata": metadata or {},
            "transcription": transcription_data,
            "teacher_child_analysis": teacher_child_analysis,
            "analyses": {
                # ê° ë¶„ì„ ìœ í˜•ë³„ ê²°ê³¼ ì €ì¥
                "comprehensive": None,
                "quick_feedback": None,
                "child_development": None,
                "coaching_tips": None,
                "sentiment_interpretation": None
            },
            "analysis_status": {
                # ê° ë¶„ì„ì˜ ì™„ë£Œ ìƒíƒœ
                "comprehensive": False,
                "quick_feedback": False,
                "child_development": False,
                "coaching_tips": False,
                "sentiment_interpretation": False
            }
        }
        
        # ì´ˆê¸° ë°ì´í„° ì €ì¥
        self._save_analysis_data(conversation_id, analysis_data)
        
        return analysis_data
    
    def update_analysis_result(self, conversation_id: str, analysis_type: str, 
                             result: Dict[str, Any]) -> bool:
        """
        íŠ¹ì • ë¶„ì„ ìœ í˜•ì˜ ê²°ê³¼ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        
        Args:
            conversation_id: ëŒ€í™” ID
            analysis_type: ë¶„ì„ ìœ í˜• ('comprehensive', 'quick_feedback' ë“±)
            result: ë¶„ì„ ê²°ê³¼
            
        Returns:
            bool: ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
            analysis_data = self.load_analysis(conversation_id)
            if not analysis_data:
                return False
            
            # ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸
            analysis_data["analyses"][analysis_type] = result
            analysis_data["analysis_status"][analysis_type] = result.get("success", False)
            analysis_data["last_updated"] = datetime.now().isoformat()
            
            # ì €ì¥
            return self._save_analysis_data(conversation_id, analysis_data)
            
        except Exception as e:
            print(f"ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def load_analysis(self, conversation_id: str, username: str = None) -> Optional[Dict[str, Any]]:
        """
        ì €ì¥ëœ ë¶„ì„ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Args:
            conversation_id: ëŒ€í™” ID
            username: ì‚¬ìš©ìëª… (ì„ íƒì‚¬í•­)
            
        Returns:
            Optional[Dict]: ë¶„ì„ ë°ì´í„° (ì—†ìœ¼ë©´ None)
        """
        # ì‚¬ìš©ìë³„ ë””ë ‰í„°ë¦¬ì—ì„œ ë¨¼ì € ì°¾ê¸°
        if username:
            user_file_path = self.results_dir / username / f"{conversation_id}.json"
            if user_file_path.exists():
                try:
                    with open(user_file_path, 'r', encoding='utf-8') as f:
                        return json.load(f)
                except Exception as e:
                    print(f"ë¶„ì„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ ë””ë ‰í„°ë¦¬ì—ì„œ ì°¾ê¸° (í•˜ìœ„ í˜¸í™˜ì„±)
        default_file_path = self.results_dir / f"{conversation_id}.json"
        if default_file_path.exists():
            try:
                with open(default_file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"ë¶„ì„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return None
    
    def get_analysis_result(self, conversation_id: str, analysis_type: str, username: str = None) -> Optional[Dict[str, Any]]:
        """
        íŠ¹ì • ë¶„ì„ ìœ í˜•ì˜ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            conversation_id: ëŒ€í™” ID
            analysis_type: ë¶„ì„ ìœ í˜•
            username: ì‚¬ìš©ìëª… (ì„ íƒì‚¬í•­)
            
        Returns:
            Optional[Dict]: ë¶„ì„ ê²°ê³¼ (ì—†ìœ¼ë©´ None)
        """
        analysis_data = self.load_analysis(conversation_id, username=username)
        if not analysis_data:
            return None
        
        return analysis_data.get("analyses", {}).get(analysis_type)
    
    def is_analysis_completed(self, conversation_id: str, analysis_type: str, username: str = None) -> bool:
        """
        íŠ¹ì • ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        
        Args:
            conversation_id: ëŒ€í™” ID  
            analysis_type: ë¶„ì„ ìœ í˜•
            username: ì‚¬ìš©ìëª… (ì„ íƒì‚¬í•­)
            
        Returns:
            bool: ì™„ë£Œ ì—¬ë¶€
        """
        analysis_data = self.load_analysis(conversation_id, username=username)
        if not analysis_data:
            return False
        
        return analysis_data.get("analysis_status", {}).get(analysis_type, False)
    
    def get_analysis_status(self, conversation_id: str) -> Dict[str, bool]:
        """
        ëª¨ë“  ë¶„ì„ ìœ í˜•ì˜ ì™„ë£Œ ìƒíƒœë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            conversation_id: ëŒ€í™” ID
            
        Returns:
            Dict[str, bool]: ë¶„ì„ ìœ í˜•ë³„ ì™„ë£Œ ìƒíƒœ
        """
        analysis_data = self.load_analysis(conversation_id)
        if not analysis_data:
            return {analysis_type: False for analysis_type in self.analysis_types.keys()}
        
        return analysis_data.get("analysis_status", {})
    
    def get_all_analyses(self, username: str = None) -> List[Dict[str, Any]]:
        """
        ëª¨ë“  ì €ì¥ëœ ë¶„ì„ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            username: íŠ¹ì • ì‚¬ìš©ìì˜ ë¶„ì„ë§Œ ê°€ì ¸ì˜¬ ê²½ìš° ì‚¬ìš©ìëª…
        
        Returns:
            List[Dict]: ë¶„ì„ ëª©ë¡ (ìµœì‹ ìˆœ)
        """
        analyses = []
        
        try:
            if username:
                # íŠ¹ì • ì‚¬ìš©ìì˜ ë¶„ì„ë§Œ ê°€ì ¸ì˜¤ê¸°
                user_dir = self.results_dir / username
                if user_dir.exists():
                    json_files = list(user_dir.glob("*.json"))
                else:
                    json_files = []
            else:
                # ëª¨ë“  ë¶„ì„ ê°€ì ¸ì˜¤ê¸° (ì‚¬ìš©ìë³„ ë””ë ‰í„°ë¦¬ì™€ ê¸°ë³¸ ë””ë ‰í„°ë¦¬ ëª¨ë‘)
                json_files = list(self.results_dir.glob("*.json"))
                
                # ì‚¬ìš©ìë³„ ë””ë ‰í„°ë¦¬ë„ ê²€ìƒ‰
                for user_dir in self.results_dir.iterdir():
                    if user_dir.is_dir() and user_dir.name != "shared":
                        json_files.extend(list(user_dir.glob("*.json")))
            
            for file_path in json_files:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        
                        # ìš”ì•½ ì •ë³´ ìƒì„±
                        summary = {
                            "conversation_id": data.get("conversation_id"),
                            "created_at": data.get("created_at"),
                            "last_updated": data.get("last_updated"),
                            "username": data.get("username"),
                            "metadata": data.get("metadata", {}),
                            "transcript_preview": self._get_transcript_preview(data),
                            "completed_analyses": sum(1 for status in data.get("analysis_status", {}).values() if status),
                            "total_analyses": len(self.analysis_types),
                            "analysis_status": data.get("analysis_status", {}),
                            "file_path": str(file_path)
                        }
                        analyses.append(summary)
                        
                except Exception as e:
                    print(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ {file_path}: {e}")
                    continue
            
            # ìµœì‹ ìˆœ ì •ë ¬
            analyses.sort(key=lambda x: x.get("created_at", ""), reverse=True)
            
        except Exception as e:
            print(f"ë¶„ì„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return analyses
    
    def delete_analysis(self, conversation_id: str, username: str = None) -> bool:
        """
        ë¶„ì„ ë°ì´í„°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
        
        Args:
            conversation_id: ëŒ€í™” ID
            username: ì‚¬ìš©ìëª… (ì„ íƒì‚¬í•­)
            
        Returns:
            bool: ì‚­ì œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            deleted = False
            deleted_files = []
            
            # ì‚¬ìš©ìë³„ ë””ë ‰í„°ë¦¬ì—ì„œ ì‚­ì œ ì‹œë„
            if username:
                user_file_path = self.results_dir / username / f"{conversation_id}.json"
                if user_file_path.exists():
                    user_file_path.unlink()
                    deleted_files.append(str(user_file_path))
                    deleted = True
            
            # ê¸°ë³¸ ë””ë ‰í„°ë¦¬ì—ì„œë„ ì‚­ì œ ì‹œë„ (í•˜ìœ„ í˜¸í™˜ì„±)
            default_file_path = self.results_dir / f"{conversation_id}.json"
            if default_file_path.exists():
                default_file_path.unlink()
                deleted_files.append(str(default_file_path))
                deleted = True
            
            if deleted:
                print(f"âœ… ë¶„ì„ ì‚­ì œ ì„±ê³µ: {conversation_id} (ì‚­ì œëœ íŒŒì¼: {len(deleted_files)}ê°œ)")
            else:
                print(f"âš ï¸ ì‚­ì œí•  íŒŒì¼ ì—†ìŒ: {conversation_id}")
            
            return deleted
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì‚­ì œ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return False
    
    def search_analyses(self, keyword: str) -> List[Dict[str, Any]]:
        """
        í‚¤ì›Œë“œë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼
        """
        all_analyses = self.get_all_analyses()
        
        if not keyword:
            return all_analyses
        
        keyword_lower = keyword.lower()
        filtered_analyses = []
        
        for analysis in all_analyses:
            # ì „ì‚¬ ë¯¸ë¦¬ë³´ê¸°, ì‚¬ìš©ìëª…, ë©”íƒ€ë°ì´í„°ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
            preview = analysis.get("transcript_preview", "").lower()
            username = analysis.get("username", "").lower()
            metadata = analysis.get("metadata", {})
            child_name = metadata.get("child_name", "").lower()
            description = metadata.get("description", "").lower()
            
            if (keyword_lower in preview or 
                keyword_lower in username or
                keyword_lower in child_name or
                keyword_lower in description):
                filtered_analyses.append(analysis)
        
        return filtered_analyses
    
    def _save_analysis_data(self, conversation_id: str, data: Dict[str, Any]) -> bool:
        """ë¶„ì„ ë°ì´í„°ë¥¼ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
        # ì‚¬ìš©ìë³„ ë””ë ‰í„°ë¦¬ êµ¬ì¡° ìƒì„±
        username = data.get('username')
        if username:
            user_dir = self.results_dir / username
            user_dir.mkdir(exist_ok=True)
            file_path = user_dir / f"{conversation_id}.json"
        else:
            # ì‚¬ìš©ìê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë””ë ‰í„°ë¦¬ ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜ì„±)
            file_path = self.results_dir / f"{conversation_id}.json"
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            print(f"ë¶„ì„ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def _get_transcript_preview(self, data: Dict[str, Any], max_length: int = 100) -> str:
        """ì „ì‚¬ë³¸ì˜ ë¯¸ë¦¬ë³´ê¸° í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        transcript = data.get("transcription", {}).get("transcript", "")
        
        if len(transcript) <= max_length:
            return transcript
        
        return transcript[:max_length] + "..."
    
    def get_analysis_types(self) -> Dict[str, Dict[str, str]]:
        """ì§€ì›í•˜ëŠ” ë¶„ì„ ìœ í˜• ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.analysis_types.copy()
    
    def export_analysis(self, conversation_id: str, format_type: str = "json") -> Optional[str]:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ ë‚´ë³´ëƒ…ë‹ˆë‹¤.
        
        Args:
            conversation_id: ëŒ€í™” ID
            format_type: ë‚´ë³´ë‚´ê¸° í˜•ì‹ ('json', 'txt')
            
        Returns:
            Optional[str]: ë‚´ë³´ë‚¸ íŒŒì¼ ê²½ë¡œ
        """
        analysis_data = self.load_analysis(conversation_id)
        if not analysis_data:
            return None
        
        try:
            if format_type == "json":
                export_path = self.results_dir / f"{conversation_id}_export.json"
                with open(export_path, 'w', encoding='utf-8') as f:
                    json.dump(analysis_data, f, ensure_ascii=False, indent=2)
                return str(export_path)
            
            elif format_type == "txt":
                export_path = self.results_dir / f"{conversation_id}_export.txt"
                with open(export_path, 'w', encoding='utf-8') as f:
                    self._write_text_report(f, analysis_data)
                return str(export_path)
            
        except Exception as e:
            print(f"ë¶„ì„ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
        
        return None
    
    def _write_text_report(self, file, data: Dict[str, Any]):
        """í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."""
        file.write(f"KindCoach ë¶„ì„ ë³´ê³ ì„œ\n")
        file.write(f"=" * 50 + "\n\n")
        file.write(f"ëŒ€í™” ID: {data.get('conversation_id', 'N/A')}\n")
        file.write(f"ë¶„ì„ ì¼ì‹œ: {data.get('created_at', 'N/A')}\n")
        file.write(f"ìµœì¢… ìˆ˜ì •: {data.get('last_updated', 'N/A')}\n\n")
        
        # ì „ì‚¬ë³¸
        transcript = data.get("transcription", {}).get("transcript", "")
        if transcript:
            file.write("ğŸ“ ëŒ€í™” ì „ì‚¬\n")
            file.write("-" * 20 + "\n")
            file.write(transcript + "\n\n")
        
        # ê° ë¶„ì„ ê²°ê³¼
        analyses = data.get("analyses", {})
        for analysis_type, result in analyses.items():
            if result and result.get("success"):
                analysis_info = self.analysis_types.get(analysis_type, {})
                file.write(f"{analysis_info.get('icon', 'ğŸ“‹')} {analysis_info.get('name', analysis_type)}\n")
                file.write("-" * 30 + "\n")
                
                if analysis_type == "comprehensive":
                    file.write(result.get("analysis", "") + "\n\n")
                elif analysis_type == "quick_feedback":
                    file.write(result.get("feedback", "") + "\n\n")
                elif analysis_type == "child_development":
                    file.write(result.get("development_analysis", "") + "\n\n")
                elif analysis_type == "coaching_tips":
                    file.write(result.get("coaching_tips", "") + "\n\n")
                elif analysis_type == "sentiment_interpretation":
                    file.write(result.get("interpretation", "") + "\n\n")